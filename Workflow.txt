1. TOOLS AND LIBRARIES:
------------------------

1.1. Fullstack Framework:
- Next.js 15.3.1 with TypeScript
- App Router architecture for server-side and client-side rendering

1.2. AI/ML Services:
- Google Cloud Platform (GCP) Vertex AI (Model = Imagen 3.0-generate-002)
- GCP Vision API for image analysis
- @google-cloud/vertexai (sdk) for Vertex AI integration 
- @google-cloud/vision (sdk) for Vision API integration

1.3. UI Components:
- Shadcn UI components
- Tailwind CSS for styling

1.4. Data Handling:
- Axios for API requests
- Next Js in built Fns for file uploads
- UUID for unique filename generation
- Zod for runtime type checking

2. WORKFLOW PIPELINE:
----------------------

1. Image Upload → /api/generate route
2. Vision API Analysis → Extract outfit details
3. Prompt Generation → Based on occasion and outfit details
4. Image Generation → Vertex AI Imagen
5. Save & Display → Store in public/output

3. MAIN FILES -->>>>>>>>>>>>

1> api/generate/route.ts ->
https://github.com/Tech-Soumyo/outfits-crazy/blob/main/src/app/api/generate/route.ts

2> lib/vision.ts ->
https://github.com/Tech-Soumyo/outfits-crazy/blob/main/src/lib/vision.ts

4. OUTFIT CONSISTENCY WITH VISION API:
----------------------------------------

- Image uploaded → Vision API analyzes:
--- Original outfit colors preserved in prompts
--- Specific garment types maintained across variations
--- Consistent model gender specified in prompts
--- Style transfer while maintaining core outfit elements

5. AUTOMATION CODE:
--------------------

5.1 Vision API Inegration: 

From Vision.ts ->

import vision from "@google-cloud/vision";

const client = new vision.ImageAnnotatorClient({
  keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS,
});

export async function analyzeImageDetails(imagePath: string) {
  const [labelResult] = await client.labelDetection(imagePath);
  const [colorResult] = await client.imageProperties(imagePath);
  const [objectResult] = await client.objectLocalization!(imagePath);

  // Process and return structured data

  return { labels, colors, objects };
}


5.2. Prompt Generation:

From generate/route.ts -> 

function prompts(
  outfit: OutfitDetails,
  occasion: "Office" | "Party" | "Vacation",
  gender: "Male" | "Female"
): string {
  const vision = `${outfit.colors[0]} ${outfit.labels.join(" ")}`;
  const genderOption = gender === "Male" ? "male model" : "female model";
  switch (occasion) {
    case "Office":
      return `A high-end editorial fashion photograph featuring a ${genderOption} model dressed in 
              a complete outfit inspired by a ${vision}. The look ........`;

    case "Party":
      return `A striking editorial fashion photograph of a ${genderOption} model wearing a full 
              outfit inspired by a ${vision}, styled ........`;

    case "Vacation":
      return `An editorial-style fashion photo featuring a ${genderOption} model in a full 
              vacation-ready outfit inspired by a ${vision}.....`;

    default:
      throw new Error("Invalid occasion");
  }



5.3 Image Generation: 

From generate/route.ts -> 

 const { image } = await generateImage({
      model: vertex.image(process.env.GCP_VERTEX_MODEL!),
      prompt,
      n: 1,
    });

5.4 File Handling:

From generate/route.ts -> 

const filename = `outfit_${uuidv4().slice(
      0,
      3
    )}_${occasion}_${gender}.${extension}`;
    const filePath = path.join(outputDir, filename);

    await fs.writeFile(filePath, Buffer.from(image.uint8Array));
    console.log(`✅ Image saved at ${filePath}`);
    const imagePath = `/output/${filename}`;

6. ENVIRONMENT SETUP:
---------------------

GOOGLE_VERTEX_PROJECT 
GOOGLE_VERTEX_LOCATION
GCP_VERTEX_MODEL= imagen-3.0-generate-002
GOOGLE_APPLICATION_CREDENTIALS

7. DIRECTORY STRUCTURE:
-------------------------
- public/
  - output/ (generated images)
  - uploads/ (original uploads)
- src/
  - app/api/generate/route.ts (Next.js app router)
  - components/ (React components)
  - lib/vision.ts (utility functions)
























